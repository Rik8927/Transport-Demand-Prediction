{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "RoGjAbkUYoAp",
        "y-Ehk30pYrdP",
        "qYpmQ266Yuh3",
        "Seke61FWphqN",
        "b0JNsNcRphqO",
        "rFu4xreNphqO",
        "lssrdh5qphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "578E2V7j08f6",
        "67NQN5KX2AMe",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "TfvqoZmBfxKf",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "7AN1z2sKpx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "HvGl1hHyA_VK",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rik8927/Transport-Demand-Prediction/blob/main/Transport_Demand_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -Transport Demand Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -**Arghya Roy\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This challenge asks you to build a model that predicts the number of seats that Mobiticket can expect to sell for each ride, i.e. for a specific route on a specific date and time. There are 14 routes in this dataset. All of the routes end in Nairobi and originate in towns to the North-West of Nairobi towards Lake Victoria.\n",
        "\n",
        "\n",
        "1.   Get the details of the datagrame\n",
        "2.   Null column abolished\n",
        "3. Merge the necessary column and create a new dataframe\n",
        "4. Train the dataset\n",
        "5. implement Machie learning model\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**The towns from which these routes originate are:\n",
        "Awendo Homa Bay Kehancha Kendu Bay Keroka Keumbu Kijauri Kisii Mbita Migori Ndhiwa Nyachenge Oyugis Rodi Rongo Sirare Sori The routes from these 14 origins to the first stop in the outskirts of Nairobi takes approximately 8 to 9 hours from time of departure. From the first stop in the outskirts of Nairobi into the main bus terminal, where most passengers get off, in Central Business District, takes another 2 to 3 hours depending on traffic. The three stops that all these routes make in Nairobi (in order) are: Kawangware: the first stop in the outskirts of Nairobi Westlands Afya Centre: the main bus terminal where most passengers disembark All of these points are mapped here. Passengers of these bus (or shuttle) rides are affected by Nairobi traffic not only during their ride into the city, but from there they must continue their journey to their final destination in Nairobi wherever that may be. Traffic can act as a deterrent for those who have the option to avoid buses that arrive in Nairobi during peak traffic hours. On the other hand, traffic may be an indication for people’s movement patterns, reflecting business hours, cultural events, political events, and holidays.\n",
        "##**Data Description\n",
        "Nairobi Transport Data.csv (zipped) is the dataset of tickets purchased from Mobiticket for the 14 routes from “up country” into Nairobi between 17 October 2017 and 20 April 2018. This dataset includes the variables: ride_id, seat_number, payment_method, payment_receipt, travel_date, travel_time, travel_from, travel_to, car_type, max_capacity. Uber Movement traffic data can be accessed here. Data is available for Nairobi through June 2018. Uber Movement provided historic hourly travel time between any two points in Nairobi. Any tables that are extracted from the Uber Movement platform can be used in your model.\n",
        "##**Variables description:\n",
        "ride_id: unique ID of a vehicle on a specific route on a specific day and time. seat_number: seat assigned to ticket payment_method: method used by customer to purchase ticket from Mobiticket (cash or Mpesa) payment_receipt: unique id number for ticket purchased from Mobiticket travel_date: date of ride departure. (MM/DD/YYYY) travel_time: scheduled departure time of ride. Rides generally depart on time. (hh:mm) travel_from: town from which ride originated travel_to: destination of ride. All rides are to Nairobi. car_type: vehicle type (shuttle or bus) max_capacity: number of seats on the vehicle"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataset = pd.read_csv('/content/train_revised.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.tail()"
      ],
      "metadata": {
        "id": "XqnucgGufzTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this dataframe 51645 rows and 10 columns."
      ],
      "metadata": {
        "id": "3a4gEkXOF6zI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.describe(include='object')"
      ],
      "metadata": {
        "id": "vIhe7Uyjg572"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_count = dataset.duplicated().sum()\n",
        "print(duplicate_count)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we can see there is no duplicate values present."
      ],
      "metadata": {
        "id": "UA3n3__YGO2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We dont see any null values here. so let's explore the dataset."
      ],
      "metadata": {
        "id": "VU57jNyzhJbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(dataset.isnull(), cmap='viridis', cbar=False, yticklabels=False)\n",
        "plt.title('Missing Values Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "so,\n",
        "\n",
        "#####There are 61 unique seats in the dataset.\n",
        "#####Traveller is used 2 type of payment method and most of the people used Mpesa to pay for their ticket.\n",
        "#####The record of 149 days out of 2 year is present in this dataset. There are 2 different types of car and most of them are bus."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "column = dataset.columns\n",
        "column"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "dataset.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The describe method told us everything chart wise.we can easily check it from there."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "dataset.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready."
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "dataset['travel_from'].value_counts().plot(kind='bar')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To vsualize from which city travel the most."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clear from the above chart that FROM\n",
        "#### 1. kisii travel most of the passengers.\n",
        "    2.Migori\n",
        "    3.Homa Bay\n",
        "    4.Sirare\n",
        "    5.Rongo\n",
        "    6.Kehancha\n",
        "    7.Awendo\n",
        "    8.Kijauri\n",
        "    9.Keroka\n",
        "    10.Nyachenge\n",
        "    11.Rodi\n",
        "    12.Mbita\n",
        "    13.Ndhiwa\n",
        "    14.Sori\n",
        "    15.Keumba\n",
        "    16.oyugis\n",
        "    17.Kendu Bay"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can easily detect from which city travel the most."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "dataset['travel_time'].value_counts().plot(kind='line')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out at what time presure of passenger is excessive."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above graph it is clear that,7 to 9 am the passenger pressure is excessive."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By finding that we an easily manage the crowd."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "dataset['car_type'].value_counts().plot(kind='bar')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which type of vehicle more preffered by pasenger."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "so we can clearly shown that,bus is most prefered by the passenger."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Plotting the target variable 'number_of_ticket'\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "ax = fig.gca()\n",
        "sns.histplot(x='payment_method', data=dataset, color='#ad1759')\n",
        "sns.set_theme(style='darkgrid')\n",
        "plt.xticks(rotation=90)\n",
        "# ax.set_xlabel('travel_from')\n",
        "# ax.set_ylabel('Frequency')\n",
        "ax.set_title('Disbribution of number_of_ticket')"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In which payment method customer pay the most."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through,Mpesa customer pay the most."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "ax = fig.gca()\n",
        "sns.histplot(x='travel_from', data=dataset, hue='travel_from', palette='rocket')\n",
        "sns.set_theme(style='darkgrid')\n",
        "plt.xticks(rotation=90)\n",
        "# ax.set_xlabel('travel_from')\n",
        "# ax.set_ylabel('Frequency')\n",
        "ax.set_title('travel_from counts')"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out from which stop the passenger is maximum."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We found that,from Kisii passenger travel maximum."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "ax = fig.gca()\n",
        "sns.countplot(x='max_capacity', data=dataset, hue='max_capacity', palette='rocket')\n",
        "sns.set_theme(style='darkgrid')\n",
        "ax.set_xlabel('max_capacity')\n",
        "# ax.set_ylabel('Frequency')\n",
        "ax.set_title('max_capacity counts')"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out the maximum capacity of the passenger."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "so, the maximum capacity of the passenger is 49."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "label=dataset.groupby([\"ride_id\"]).seat_number.count().rename(\"number_of_ticket\").reset_index()\n",
        "label.head()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=dataset.drop_duplicates(\"ride_id\")\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "OZNMoRiH5Yqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.merge(label, how=\"left\",on=\"ride_id\")\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "MufyACKA5f7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data=dataset,x='travel_from',y='number_of_ticket')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Total tickets from each origin place')\n"
      ],
      "metadata": {
        "id": "b3ajhBzK5XCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out which place has most number of ticket."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "so from the baove graph it is clear that,Sirare has the most number of tickets."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Chart - 1 visualization code\n",
        "dataset['travel_to'].value_counts().plot(kind='bar')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "where the passenger travel most."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can cleraly see that,Nairobi is the place where they travle most."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing Constant Features\n",
        "#Lets first remove the constant features\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "dataset.drop([\"travel_to\"],axis=1,inplace=True)\n",
        "plt.figure(figsize=(20, 15))\n",
        "sp = sns.scatterplot(x=\"travel_from\", y=\"number_of_ticket\", data=dataset)"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out where the number of ticket sale is high."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can find out in siarre number of ticket sale is high."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Checking the coorelation between independent variables\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.heatmap(dataset.corr().abs(),  annot=True)"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out the correlation."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that, number_of _ticket and ride-id correlatioin is high."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "# pairplot with hue sex\n",
        "seaborn.pairplot(dataset)\n",
        "# to show\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the overiew."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "so from the above pairplot,we can get a clear view of in which sector what rating we get."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0):\n",
        "\n",
        "H0: There is no significant association between travel_from and number_of_ticket.\n",
        "In both cases, the null hypothesis suggests that there is no relationship or association between the two categorical variables.\n",
        "\n",
        "Alternative Hypothesis (Ha):\n",
        "Ha: There is a significant association between travel_frome and number_of_ticket.\n",
        "The alternative hypothesis suggests that there is a significant relationship or association between the two categorical variable. chi-square test for independence to analyze the data and determine whether the p-value obtained from the test is less than the chosen significance level (e.g., α = 0.05). If the p-value is less than α, we can reject the null hypothesis, indicating that there is a significant association between passenger type and referral behavior. If the p-value is greater than α, we would fail to reject the null hypothesis, suggesting no significant association."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head(1)"
      ],
      "metadata": {
        "id": "NysnMcErCizT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import chi2_contingency\n",
        "contingency_table = pd.crosstab(dataset['travel_from'], dataset['number_of_ticket'])\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "print(f\"Chi-Square Test Statistic: {chi2}\")\n",
        "print(f\"P-value: {p}\")\n",
        "if p < 0.05:\n",
        "    print(\"Reject the null hypothesis: There is a significant relationship between travel_from and number_of_ticket.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant relationship between travel_from and number_of_ticket.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "chi-square test."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chi-square test helps to determine whether there is a statistically significant association or relationship between two categorical variables—in this case,travel_from and number_of_ticket. This can help you understand if the travel distance help to understand transport demand."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0):\n",
        "\n",
        "H0: There is no significant association between travel_from and number_of_ticket. In both cases, the null hypothesis suggests that there is no relationship or association between the two categorical variables.\n",
        "\n",
        "Alternative Hypothesis (Ha): Ha: There is a significant association between travel_from and number_of_ticket. The alternative hypothesis suggests that there is a significant relationship or association between the two categorical variable. chi-square test for independence to analyze the data and determine whether the p-value obtained from the test is less than the chosen significance level (e.g., α = 0.05). If the p-value is less than α, we can reject the null hypothesis, indicating that there is a significant association between travel_from and number_of_ticket. If the p-value is greater than α, we would fail to reject the null hypothesis, suggesting no significant association."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import chi2_contingency\n",
        "contingency_table = pd.crosstab(dataset['travel_from'], dataset['number_of_ticket'])\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table, lambda_=\"log-likelihood\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if p < 0.05:\n",
        "    print(\"Reject the null hypothesis: There is a significant relationship between travel_from and number_of_ticket.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant relationship between travel_from and number_of_ticket.\")"
      ],
      "metadata": {
        "id": "RLClw_PjOZEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "G-test."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of transport demand prediction, we may want to use the G-test to determine if there is a statistically significant association between the travel_from and the number_of_ticket. If the relation between travel_from and number_of_ticket is suitable then the demand prediction is good.so,we can set our plan according to that."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0):\n",
        "\n",
        "Null Hypothesis: The coefficient (β) for a specific predictor variable in the logistic regression model is equal to zero.\n",
        "Symbolically: H0: β = 0\n",
        "Interpretation: This null hypothesis assumes that the predictor has no effect on the log-odds of the binary outcome variable. In other words, the predictor is not associated with the outcome.\n",
        "Alternative Hypothesis (Ha):\n",
        "\n",
        "Alternative Hypothesis: The coefficient (β) for a specific predictor variable in the logistic regression model is not equal to zero.\n",
        "Symbolically: Ha: β ≠ 0\n",
        "Interpretation: The alternative hypothesis suggests that the predictor has a statistically significant effect on the log-odds of the binary outcome variable. In other words, the predictor is associated with the outcome."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import statsmodels.api as sm\n",
        "df_cleaned = dataset.dropna()\n",
        "df_cleaned['ride_id'] = df_cleaned['ride_id'].apply(lambda x: 1 if x > 0.5 else 0)\n",
        "df_cleaned['number_of_ticket'] = df_cleaned['number_of_ticket'].apply(lambda x: 1 if x > 0.5 else 0)\n",
        "X = df_cleaned[['ride_id', 'number_of_ticket']]\n",
        "X = pd.get_dummies(X, columns=['ride_id'], drop_first=True)  # Dummy encode passenger type\n",
        "y = df_cleaned['number_of_ticket']\n",
        "X = sm.add_constant(X)  # Add a constant (intercept) term\n",
        "model = sm.Logit(y, X)\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if p < 0.05:\n",
        "    print(\"Reject the null hypothesis: There is a significant relationship between ride_id and number_of_ticket.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant relationship between ride_id and number_of_ticket.\")"
      ],
      "metadata": {
        "id": "5Ylsy3emQek-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression provides easily interpretable results. You can interpret the coefficients of predictor variables as the log-odds of the outcome, allowing you to understand how each predictor influences the likelihood of a referral. This interpretability can be valuable for making business decisions."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "6Em5OQdARu3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "# Lower Casing\n",
        "def remove_stopwords(text):\n",
        "    '''a function for removing the stopword'''\n",
        "    # removing the stop words and lowercasing the selected words\n",
        "    #Method 1\n",
        "    text1 = [word.lower() for word in text.split() if word.lower() not in sw]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text1)"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    import string\n",
        "    # replacing the punctuations with no space,\n",
        "    # which in effect deletes the punctuation marks\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['seat_number'] = dataset['seat_number'].apply(remove_punctuation)\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "k9uJL4jTSJzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "#concatinate travel date and travel time column and make a new feature called date.\n",
        "dataset[\"date\"]=dataset[\"travel_date\"]+ \" \"+dataset[\"travel_time\"]"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def  time_features(df):\n",
        "\n",
        "  '''This function takes dataframe as an argument and extracts the\n",
        "  different features from the date variable of the dataset and finaly returns the updated\n",
        "  dataset'''\n",
        "\n",
        "  df[\"date\"]=pd.to_datetime(df[\"date\"])\n",
        "  df[\"day_of_week\"]=df[\"date\"].dt.dayofweek\n",
        "  df[\"day_of_year\"]=df[\"date\"].dt.dayofyear\n",
        "  df[\"day_of_month\"]=df[\"date\"].dt.day\n",
        "  df[\"year_woy\"]=df[\"date\"].dt.year.astype(str)+df[\"date\"].dt.weekofyear.astype(str)\n",
        "  df[\"hour\"]=df[\"date\"].dt.hour\n",
        "  df[\"minute\"]=df[\"date\"].dt.minute\n",
        "  df[\"is_weekend\"]=df[\"day_of_week\"].apply( lambda x : 1 if x  in [5,6] else 0 )\n",
        "  df[\"year\"]=df[\"date\"].dt.year\n",
        "  df[\"quarter\"]=df[\"date\"].dt.quarter\n",
        "  df[\"month\"]=df[\"date\"].dt.month\n",
        "  return df"
      ],
      "metadata": {
        "id": "J0vplDd6gBPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_new = time_features(dataset)\n",
        "dataset_new.head()"
      ],
      "metadata": {
        "id": "Fz4JY_GigEjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there is the gap between 5 to 11 in the day of the month. We can assume that there is official holiday of public transport between these days. we can also say that the number of tickets in all the days of month are same."
      ],
      "metadata": {
        "id": "LeQiwVxmgQLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "sns.scatterplot(x='day_of_month', y=\"number_of_ticket\", data=dataset)"
      ],
      "metadata": {
        "id": "PpD2jZx0gPXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "sns.scatterplot(x='hour', y=\"number_of_ticket\", data=dataset)"
      ],
      "metadata": {
        "id": "0KAuoz9PgXcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that most of the ticktes were sold at 7 AM and 8 PM. And that seems true because in the morning most of the people go to the work and office.\n",
        "\n",
        "From the above we can say that there is not ride between 12pm to 5.30Pm\n",
        "\n"
      ],
      "metadata": {
        "id": "s72Bxni5ggkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "dataset_new[\"travel_time\"] = dataset_new[\"travel_time\"].str.split(':').apply(lambda x: int(x[0]) + int(x[1])/60)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_new['period'] = np.nan\n",
        "dataset_new.loc[dataset_new.travel_time < 7, 'period'] = 'em'\n",
        "dataset_new.loc[(dataset_new.travel_time >= 7) & (dataset_new.travel_time < 11), 'period'] = 'am'\n",
        "dataset_new.loc[(dataset_new.travel_time >= 11) & (dataset_new.travel_time < 15), 'period'] = 'mid'\n",
        "dataset_new.loc[(dataset_new.travel_time >= 15) & (dataset_new.travel_time < 19), 'period'] = 'eve'\n",
        "dataset_new.loc[(dataset_new.travel_time >= 19) & (dataset_new.travel_time <= 24), 'period'] = 'pm'\n",
        "\n",
        "\n",
        "pcount = dict(dataset_new['period'].value_counts())\n",
        "pcount\n",
        "\n",
        "\n",
        "dataset_new['hourly_travelers'] = np.log1p(dataset_new['period'].map(pcount))\n",
        "\n",
        "\n",
        "\n",
        "dcount = dict(dataset_new[\"day_of_year\"].value_counts())\n",
        "dataset_new[\"daily_travelers\"] = np.log1p(dataset_new[\"day_of_year\"].map(dcount))\n",
        "dataset_new.head()"
      ],
      "metadata": {
        "id": "XqkoKNmogz2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_new.columns"
      ],
      "metadata": {
        "id": "LT45yZOhg8U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_cols = ['day_of_year','daily_travelers','minute','day_of_month','hourly_travelers','is_weekend','day_of_week']"
      ],
      "metadata": {
        "id": "5NZkVrZyh_cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transport_dataset=dataset_new.copy()"
      ],
      "metadata": {
        "id": "zMwJJZ1op5JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transport_dataset.head()"
      ],
      "metadata": {
        "id": "sVu0dMjqp7kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transport_dataset.shape"
      ],
      "metadata": {
        "id": "d28of8OliLua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transport_dataset.month.value_counts()"
      ],
      "metadata": {
        "id": "Gb5gBiMxiPB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_cov = {12:1,2:1,1:1,2:1,4:2,11:2,9:3,7:3,8:3,10:3,6:3,5:3}\n",
        "transport_dataset['month'].replace(dict_cov,inplace=True)\n",
        "transport_dataset.month.value_counts()"
      ],
      "metadata": {
        "id": "Y-I-5QvHiTEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transport_dataset.day_of_month.unique()"
      ],
      "metadata": {
        "id": "ERbpm9_uipKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_dict = {17:2, 19:2, 26:3, 27:3, 20:2, 18:2, 16:2, 15:2, 14:2, 13:2,  4:1, 28:2, 31:3, 30:3, 29:3, 25:3, 24:3,\n",
        "       23:3, 22:3, 21:3, 12:1,  3:1,  2:1,  1:2}\n",
        "transport_dataset['day_of_month'].replace(conv_dict,inplace=True)"
      ],
      "metadata": {
        "id": "PtcgrvSHqG5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transport_dataset['day_of_month'].value_counts()"
      ],
      "metadata": {
        "id": "hkWHj6JyqLzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transport_dataset.head()"
      ],
      "metadata": {
        "id": "rkSQC_ytisTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shift index by desired number of periods with an optional time frequency.\n",
        "\n",
        "When freq is not passed, shift the index without realigning the data. If freq is passed (in this case, the index must be date or datetime, or it will raise a NotImplementedError), the index will be increased using the periods and the freq. freq can be inferred when specified as “infer” as long as either freq or inferred_freq attribute is set in the index.\n",
        "\n",
        "Series-dt.total_seconds() function:- The dt.total_seconds() function is used to return total duration of each element expressed in seconds."
      ],
      "metadata": {
        "id": "B4XgdtjDi0a6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "def find_difference_bw_bus(data):\n",
        "\n",
        "  data.sort_values([\"travel_from\",\"date\"],inplace=True,ascending=True)\n",
        "  data[\"Time_gap_btw_0_1_next_bus\"]=(data[\"date\"]-data.groupby([\"travel_from\"]).date.shift(-1)).dt.total_seconds()/3600\n",
        "  data[\"Time_gap_btw_0_1_previous_bus\"]=(data[\"date\"]-data.groupby([\"travel_from\"]).date.shift(1)).dt.total_seconds()/3600\n",
        "  data[\"Time_gap_btw_0_2_next_bus\"]=(data[\"date\"]-data.groupby([\"travel_from\"]).date.shift(-2)).dt.total_seconds()/3600\n",
        "  data[\"Time_gap_btw_0_2_previous_bus\"]=(data[\"date\"]-data.groupby([\"travel_from\"]).date.shift(2)).dt.total_seconds()/3600\n",
        "  data[\"Time_gap_btw_0_3_next_bus\"]=(data[\"date\"]-data.groupby([\"travel_from\"]).date.shift(-3)).dt.total_seconds()/3600\n",
        "  data[\"Time_gap_btw_0_3_previous_bus\"]=(data[\"date\"]-data.groupby([\"travel_from\"]).date.shift(3)).dt.total_seconds()/3600\n",
        "  data[\"Time_gap_btw_next_previous_bus\"]=(data.groupby([\"travel_from\"]).date.shift(-1)-data.groupby([\"travel_from\"]).date.shift(1)).dt.total_seconds()/3600\n",
        "  cols=[\"Time_gap_btw_0_1_next_bus\", \"Time_gap_btw_0_1_previous_bus\", \"Time_gap_btw_0_2_next_bus\",\"Time_gap_btw_0_2_previous_bus\",\n",
        "      \"Time_gap_btw_0_3_next_bus\", \"Time_gap_btw_0_3_previous_bus\",\n",
        "      \"Time_gap_btw_next_previous_bus\"]\n",
        "  data[cols]=data.groupby([\"travel_from\"])[cols].fillna(method=\"ffill\")\n",
        "  data[cols]=data.groupby([\"travel_from\"])[cols].fillna(method=\"backfill\")\n",
        "\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = find_difference_bw_bus(transport_dataset)"
      ],
      "metadata": {
        "id": "uzKUBYM2jvsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "QT8l_qMPjymX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that there are some null values present in the dataset so let us reomove those null values."
      ],
      "metadata": {
        "id": "0Hri7vZkj13e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "_vcly1D8j5Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from datetime import timedelta"
      ],
      "metadata": {
        "id": "uBnaO8OpkFGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance = {'Migori': 370 , 'Keroka': 280, 'Homa Bay':360, 'Kisii':305.1, 'Keumbu':295, 'Rongo':332,\n",
        "'Kijauri':271, 'Oyugis':330.6, 'Awendo':351, 'Sirare':392, 'Nyachenge':326, 'Kehancha': 387.7,\n",
        "'Kendu Bay':347, 'Sori':399, 'Rodi':348, 'Mbita':401, 'Ndhiwa': 371}\n",
        "data[\"travel_from_distance\"]=data.travel_from.map(distance)"
      ],
      "metadata": {
        "id": "yQZhbmG4kIHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time = {'Migori': 7*60+8 , 'Keroka': 5*60, 'Homa Bay':7*60, 'Kisii':5*60+34, 'Keumbu':5*60+20, 'Rongo':6*60+21,\n",
        "'Kijauri':60*4+50,'Oyugis':5*60+50, 'Awendo':6*60+38, 'Sirare':7*60+30, 'Nyachenge':6*60+10, 'Kehancha':7*60+10,\n",
        "'Kendu Bay':6*60+10, 'Sori':7*60+30, 'Rodi':6*60+40, 'Mbita':7*60+23, 'Ndhiwa': 7*60}\n",
        "data[\"travel_from_time\"]=data.travel_from.map(time)"
      ],
      "metadata": {
        "id": "iEhVUtRiqgJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Speed\"]=data.travel_from_time/data.travel_from_distance"
      ],
      "metadata": {
        "id": "FjJ_SOXSquNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(data['Speed'],data['number_of_ticket'])"
      ],
      "metadata": {
        "id": "gobDpdjGkPhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We plot the graph between the speed and number of ticket."
      ],
      "metadata": {
        "id": "oSFN-ezqN82D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time = {'Migori': 7*60+8 , 'Keroka': 5*60, 'Homa Bay':7*60, 'Kisii':5*60+34, 'Keumbu':5*60+20, 'Rongo':6*60+21,\n",
        "'Kijauri':60*4+50,'Oyugis':5*60+50, 'Awendo':6*60+38, 'Sirare':7*60+30, 'Nyachenge':6*60+10, 'Kehancha':7*60+10,\n",
        "'Kendu Bay':6*60+10, 'Sori':7*60+30, 'Rodi':6*60+40, 'Mbita':7*60+23, 'Ndhiwa': 7*60}\n",
        "for key in time.keys():\n",
        "    time[key]=timedelta( minutes=time[key])"
      ],
      "metadata": {
        "id": "fPxwir6wkTlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find the date of traveling from origin\n",
        "data[\"Date_of_traveling_from_origin\"]=data.travel_from.map(time)\n",
        "# find the date of arrival at distination\n",
        "data[\"arrival_date\"]=data.date+ data.Date_of_traveling_from_origin\n",
        "data[\"hod_arrived_date\"]=data[\"arrival_date\"].dt.hour\n",
        "data[\"minute_arrived_date\"]=data[\"arrival_date\"].dt.minute\n",
        "del data[\"Date_of_traveling_from_origin\"],data[\"arrival_date\"]\n",
        "data[\"is_rush_hour\"]=0\n",
        "data.loc[data.hod_arrived_date.between(7,17),\"is_rush_hour\"]=1"
      ],
      "metadata": {
        "id": "BGZxxuU9kWNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing #Import LabelEncoder\n",
        "data = pd.get_dummies(data, columns=['travel_from','day_of_month','month'])\n",
        "label_enc = {'Bus':1,'shuttle':0}\n",
        "data.replace(label_enc,inplace=True)"
      ],
      "metadata": {
        "id": "xsSCZhwRkY1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "q7FNfPeCkY9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys= [\"ride_id\"]\n",
        "Target_name=\"number_of_ticket\"\n",
        "not_used_cols=[\"ride_id\",\"seat_number\",\"payment_method\",\"payment_receipt\",\"travel_time\" ,\"travel_date\",\"date\",'year_woy','max_capacity','number_of_ticket',\n",
        "               'period'\n",
        "]"
      ],
      "metadata": {
        "id": "lYEYJfNjkeUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = data.drop(not_used_cols,axis=1).columns"
      ],
      "metadata": {
        "id": "0dgQZ3H3vDCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "vnvl52chvF1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We drop the column which is unnecessary and merge the column to create new colummn."
      ],
      "metadata": {
        "id": "MME5yvbZNrSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[features].head()"
      ],
      "metadata": {
        "id": "NAJmlSpR_ACl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(actual, predicted):\n",
        "  print('MSE is {}'.format(mean_squared_error(actual, predicted)))\n",
        "  print('RMSE is {}'.format(math.sqrt(mean_squared_error(actual, predicted))))\n",
        "  print('RMSE is {}'.format(r2_score(actual, predicted)))\n",
        "  print('MAE is {}'.format(mean_absolute_error(actual, predicted)))\n",
        "  print('MAPE is {}'.format(np.mean(np.abs((actual - predicted) / actual)) * 100))\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "used_cols = ['day_of_year']\n",
        "prev_adjR2 = -0.01177282976168792\n",
        "for col in features:\n",
        "  used_cols.append(col)\n",
        "  dataset_pr = data[used_cols]\n",
        "  X= dataset_pr.copy()\n",
        "  y = data['number_of_ticket']\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=42)\n",
        "  model =LinearRegression()"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train)\n",
        "  # Predicting\n",
        "y_pred = model.predict(X_test)\n",
        "  #Find R-squared value\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "  # Find Adjusted R-squared value\n",
        "adj_r2=1-(1-r2_score(y_test, y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))\n",
        "if prev_adjR2<adj_r2:\n",
        "    prev_adjR2 = adj_r2\n",
        "    train_score = model.score(X_train, y_train)\n",
        "    test_score = model.score(X_test,y_test)\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "else:\n",
        "    used_cols.pop()\n",
        "\n",
        "print(f'Adjust_r2: {prev_adjR2}')\n",
        "print(f'Train score: {train_score}')\n",
        "print(f'Test score: {test_score}')\n",
        "print(r2)\n",
        "print('Important features are: \\n')\n",
        "used_cols"
      ],
      "metadata": {
        "id": "Rw-lc5ElKbWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train the data near about 80% and test the data 20% to get the optimum result."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "# Fit the Algorithm\n",
        "# Predict on the model\n",
        "from sklearn.linear_model import Lasso\n",
        "X= data[used_cols].copy()\n",
        "y = data['number_of_ticket']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=42)\n",
        "alphas = [0.01,0.025,0.5,0.75,1]\n",
        "for alpha in alphas:\n",
        "  lasso  = Lasso(alpha=alpha , max_iter= 3000)\n",
        "  lasso.fit(X_train, y_train)\n",
        "  print('alpha: ',alpha)\n",
        "  print('test Score: ',lasso.score(X_test, y_test))\n",
        "  print('train Score: ',lasso.score(X_train, y_train))"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso  = Lasso(alpha=0.01 , max_iter= 3000)\n",
        "lasso.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Ekv0ApOSzdEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = lasso.predict(X_test)\n",
        "print('MSE is {}'.format(mean_squared_error(y_test, y_test_pred)))\n",
        "print('RMSE is {}'.format(math.sqrt(mean_squared_error(y_test, y_test_pred))))\n",
        "print('MAE is {}'.format(mean_absolute_error(y_test, y_test_pred)))"
      ],
      "metadata": {
        "id": "kq9OebEuzhVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = r2_score(y_test, y_test_pred)\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(y_test, y_test_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "KSCeZfuDzm7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Hyperprarameter tuning\n",
        "X= data[features].copy()\n",
        "y = data['number_of_ticket']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=42)\n",
        "ridge=Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_regressor.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "9WpQqxY-5G1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
        "print(\"\\nUsing \",ridge_regressor.best_params_, \" the negative mean squared error is: \", ridge_regressor.best_score_)"
      ],
      "metadata": {
        "id": "pLgqWZ6y5S8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV (Grid Search Cross-Validation) is used in Nairobi transport demand prediction, as well as in many other machine learning and predictive modeling tasks, for several important reasons:\n",
        "\n",
        "1.Hyperparameter Tuning: In transport demand prediction, as in other machine learning applications, the choice of hyperparameters can significantly impact the model's performance. GridSearchCV allows you to systematically search through a range of hyperparameter values to find the combination that yields the best predictive results. For example, in a transport demand prediction model, you might want to tune hyperparameters related to regularization strength, the type of regularization (e.g., L1 or L2), the choice of kernel for kernel-based methods, or the depth of decision trees in ensemble methods.\n",
        "\n",
        "2.Model Optimization: GridSearchCV helps you optimize your predictive model for transport demand by exploring different hyperparameter settings. This can lead to models that provide more accurate predictions, which is crucial for efficient transportation planning and resource allocation in a city like Nairobi.\n",
        "\n",
        "3.Improved Generalization: By using cross-validation during the grid search, you ensure that the chosen hyperparameters generalize well to new, unseen data. This is especially important in transport demand prediction, where the model needs to provide accurate predictions for different time periods, locations, and transportation scenarios.\n",
        "\n",
        "4.Performance Evaluation: GridSearchCV not only helps you find the best hyperparameters but also evaluates model performance using a defined metric (e.g., mean squared error, mean absolute error, or others). This ensures that your transport demand prediction model meets the desired accuracy and quality standards.\n",
        "\n",
        "5.Efficiency: GridSearchCV automates the process of hyperparameter tuning, making it more efficient and less error-prone compared to manually experimenting with different hyperparameter values. It tests all possible combinations from the specified hyperparameter grid, saving time and effort for the data scientist or analyst.\n",
        "\n",
        "6.Reproducibility: Using GridSearchCV in your transport demand prediction process makes your modeling approach more reproducible. It documents the hyperparameters you tested and the best-performing combination, which can be useful for future reference and model updates.\n",
        "\n",
        "7.Robustness: GridSearchCV helps you build more robust models by systematically considering various hyperparameter settings. This robustness is important in the context of transport demand prediction, where the accuracy of predictions can have significant economic and societal implications."
      ],
      "metadata": {
        "id": "7JbYsxBhX_2R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "#Model Prediction\n",
        "y_pred_ridge = ridge_regressor.predict(X_test)\n",
        "print(ridge_regressor.score(X_train,y_train))\n",
        "print(ridge_regressor.score(X_test,y_test))\n",
        "\n",
        "print_metrics(y_test, y_test_pred)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred_ridge)\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(y_test, y_pred_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "#Gradient boost regressor\n",
        "used_cols = ['day_of_year']\n",
        "prev_adjR2 = -0.01177282976168792\n",
        "for col in features:\n",
        "  used_cols.append(col)\n",
        "  dataset_pr = data[used_cols]\n",
        "  X= dataset_pr.copy()\n",
        "  y = data['number_of_ticket']\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=42)\n",
        "  reg = GradientBoostingRegressor(random_state=0)\n",
        "  reg.fit(X_train, y_train)\n",
        "  # Predicting\n",
        "  y_pred = reg.predict(X_test)\n",
        "  y_pred_train=reg.predict(X_train)\n",
        "\n",
        "\n",
        "  # Find Adjusted R-squared value\n",
        "  adj_r2=1-(1-r2_score(y_test, y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))\n",
        "  if prev_adjR2<adj_r2:\n",
        "    prev_adjR2 = adj_r2\n",
        " #Find R-squared value\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_for_train= r2_score(y_train,y_pred_train)\n",
        "    train_score = reg.score(X_train, y_train)\n",
        "    test_score = reg.score(X_test,y_test)\n",
        "  else:\n",
        "    used_cols.pop()\n",
        "\n",
        "print(f'Adjust_r2: {prev_adjR2}')\n",
        "print(f'Train score: {train_score}')\n",
        "print(f'Test score: {test_score}')\n",
        "print(f'r2_Test score: {r2}')\n",
        "print(f'r2_train score: {r2_for_train}')\n",
        "print_metrics(y_test, y_pred)\n",
        "print('Important features are: \\n')\n",
        "used_cols"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2"
      ],
      "metadata": {
        "id": "GuFGgSgm52vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj_r2"
      ],
      "metadata": {
        "id": "tNvqBk-p55VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "import xgboost as xgb\n",
        "# dataset_pr = data[]\n",
        "X = data[used_cols].copy()\n",
        "y = data['number_of_ticket'].copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=42)\n",
        "dreg= xgb.XGBRegressor(\n",
        "                        booster= 'gbtree',\n",
        "                        colsample_bylevel= 1,\n",
        "                        colsample_bynode= 1,\n",
        "                        colsample_bytree= 0.7,\n",
        "                        eta= 0.004,\n",
        "                        gamma= 0,\n",
        "                        importance_type= 'gain',\n",
        "                        learning_rate= 0.1,\n",
        "                        max_delta_step= 0,\n",
        "                        max_depth= 9,\n",
        "                        min_child_weight= 10,\n",
        "                        n_estimators= 100,\n",
        "                        n_jobs= 1,\n",
        "                        objective= 'reg:linear',\n",
        "                        random_state= 0,\n",
        "                        reg_alpha= 0,\n",
        "                        reg_lambda= 1,\n",
        "                        scale_pos_weight= 1,\n",
        "                        subsample= 1,\n",
        "                        verbosity= 1)\n",
        "dreg.fit(X_train, y_train)\n",
        "y_pred_train=dreg.predict(X_train)\n",
        "y_pred = dreg.predict(X_test)\n",
        "#Find R-squared value\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "r2_train = r2_score(y_train, y_pred_train)\n",
        "# Find Adjusted R-squared value\n",
        "adj_r2=1-(1-r2_score(y_test, y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))\n",
        "train_score = dreg.score(X_train, y_train)\n",
        "test_score = dreg.score(X_test,y_test)\n",
        "print(f'Train score: {train_score}')\n",
        "print(f'Test score: {test_score}')\n",
        "adj_r2\n",
        "r2\n",
        "r2_train"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using XGBoost (eXtreme Gradient Boosting) as a gradient boosting regressor can have a significant impact on transport demand prediction in Nairobi, or in any urban area for that matter. XGBoost is a powerful and highly effective machine learning algorithm that is known for its predictive accuracy and efficiency. Here's how XGBoost can impact transport demand prediction:\n",
        "\n",
        "Improved Predictive Accuracy:\n",
        "XGBoost is known for its excellent predictive performance. It can capture complex relationships and patterns in the data, which is crucial for accurate transport demand prediction. In an urban setting like Nairobi, where factors affecting transportation are multifaceted and dynamic, improved predictive accuracy can lead to more precise forecasts.\n",
        "\n",
        "Feature Importance:\n",
        "XGBoost provides a measure of feature importance, indicating which factors have the most impact on the predictions. Understanding which features are most influential can be valuable for urban planners and policymakers. It can help them focus their efforts and resources on addressing the most critical factors affecting transport demand.\n",
        "\n",
        "Handling Nonlinear Relationships:\n",
        "XGBoost can capture nonlinear relationships between features and transport demand. This is important because transportation dynamics often involve complex, nonlinear interactions between factors such as traffic, population growth, economic conditions, and infrastructure changes.\n",
        "\n",
        "Regularization and Overfitting Control:\n",
        "XGBoost offers several regularization techniques, which help prevent overfitting and improve the model's generalization to new data. This is important for robust and reliable transport demand predictions.\n",
        "#####In summary, using XGBoost for transport demand prediction in Nairobi can lead to more accurate, robust, and efficient models that take into account the complex and dynamic nature of transportation systems in a bustling urban area."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "from sklearn import decomposition\n",
        "from sklearn import tree\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "X = data[features].copy()\n",
        "y = data['number_of_ticket'].copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=42)\n",
        "dec_reg =RandomForestRegressor()\n",
        "dec_reg.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec_reg.score(X_train,y_train)"
      ],
      "metadata": {
        "id": "7R0Zqdhx6WSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec_reg.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "ObeQJAwm6ZBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "parameters = {  'ccp_alpha':[0.01,0.1,1,10,100],\n",
        "              'max_depth': [4, 6, 8],\n",
        "            'min_samples_leaf': [40, 50],\n",
        "            'min_samples_split': [50, 100, 150]\n",
        "}\n",
        "X = data[features].copy()\n",
        "y = data['number_of_ticket'].copy()\n",
        "dec_reg =RandomForestRegressor()\n",
        "rf_grid =GridSearchCV(dec_reg,param_grid=parameters, verbose=1,cv=2)\n",
        "rf_grid.fit(X, y)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_grid.best_estimator_.get_params()"
      ],
      "metadata": {
        "id": "ovlZ0A9m7VUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_optimal_model =rf_grid.best_estimator_\n",
        "rf_train_preds = rf_optimal_model.predict(X_train)\n",
        "rf_test_preds = rf_optimal_model.predict(X_test)\n",
        "train_score= rf_optimal_model.score(X_train,y_train)\n",
        "test_score = rf_optimal_model.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "kPiT_wj98TD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find R-squared value\n",
        "r2 = r2_score(y_test, rf_test_preds)\n",
        "r2_train = r2_score(y_train, rf_train_preds)\n",
        "# Find Adjusted R-squared value\n",
        "adj_r2=1-(1-r2_score(y_test,rf_test_preds))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))\n",
        "\n",
        "print('Train Score: ',train_score)\n",
        "print('Test Score: ',test_score)\n",
        "print('Mean Squared Error (MSE): ',mean_squared_error(y_test, rf_test_preds))\n",
        "print('Mean Absolute Error (MAE): ',mean_absolute_error(y_test, rf_test_preds))\n",
        "print('Root Mean Squared Error (MSE): ',np.sqrt(mean_squared_error(y_test, rf_test_preds)))\n",
        "print('R2 Score: ',r2)\n",
        "print('R2_train Score: ',r2_train)\n",
        "print('Adjusted R2 Score: ',adj_r2)"
      ],
      "metadata": {
        "id": "ntr-h3pc8WHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a Random Forest Regressor for transport demand prediction in Nairobi can offer several advantages and can be a suitable choice depending on the specific characteristics of the data and the problem you are trying to solve. Here are some reasons why you might choose a Random Forest Regressor for this type of prediction:\n",
        "\n",
        "Nonlinearity in Transport Demand: Random Forest is a flexible algorithm that can capture nonlinear relationships between features and the transport demand. In urban environments like Nairobi, where transportation dynamics are influenced by a variety of factors such as traffic conditions, economic conditions, population growth, and infrastructure changes, nonlinear modeling can be essential to accurately capture these complex interactions.\n",
        "\n",
        "Handling Complex Interactions: Random Forests are well-suited for capturing complex interactions between features. For example, the demand for public transportation might depend on factors like population density, time of day, and the availability of alternative transportation modes. Random Forest can handle these interactions effectively.\n",
        "\n",
        "Robustness to Noisy Data: Random Forests are generally robust to noisy data and outliers. In real-world transportation data, noise and outliers are common due to factors like irregular traffic patterns, unexpected events, and data measurement errors. Random Forests can provide stable predictions in the presence of such noise.\n",
        "\n",
        "Ensemble Learning: Random Forest is an ensemble learning method, meaning it combines the predictions of multiple decision trees to make a final prediction. This ensemble approach can lead to more accurate and robust predictions. Additionally, it reduces the risk of overfitting, which can be critical when working with limited transportation data.\n",
        "\n",
        "Feature Importance: Random Forests can provide information about the importance of each feature in making predictions. Understanding which factors have the most significant impact on transport demand can be valuable for urban planners and policymakers in Nairobi. It can help them make informed decisions about transportation infrastructure and services.\n",
        "\n",
        "Scalability and Efficiency: Random Forests can handle large datasets, making them suitable for cities with substantial amounts of transportation data. The algorithm can also parallelize the training process for increased efficiency."
      ],
      "metadata": {
        "id": "LQUc0N1idJKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model 4"
      ],
      "metadata": {
        "id": "6sWH0MhnAal9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 4\n",
        "#XG boost algorithm\n",
        "import xgboost as xgb\n",
        "xgb = xgb.XGBRegressor()\n",
        "params = {\"min_child_weight\":[10,20],\n",
        "            'eta': [0.004,0.04,4,40],\n",
        "            'colsample_bytree':[0.7],\n",
        "            'max_depth': [7,9,11],\n",
        "\n",
        "          }\n",
        "X = data[features].copy()\n",
        "y = data['number_of_ticket'].copy()\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=42)\n",
        "reg_gs = GridSearchCV(xgb,param_grid=params, verbose=1,cv=3)\n",
        "reg_gs.fit(X, y)"
      ],
      "metadata": {
        "id": "_Ah9ONYr-HA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_gs.best_estimator_.get_params()"
      ],
      "metadata": {
        "id": "wI87zLs8-i_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_optimal_model =reg_gs.best_estimator_\n",
        "train_preds = reg_optimal_model.predict(X_train)\n",
        "test_preds = reg_optimal_model.predict(X_test)\n",
        "reg_optimal_model.score(X_train,y_train)"
      ],
      "metadata": {
        "id": "zWTcmiBM-o5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find R-squared value\n",
        "r2_test = r2_score(y_test, test_preds)\n",
        "# Find Adjusted R-squared value\n",
        "adj_r2=1-(1-r2_score(y_test, test_preds))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))"
      ],
      "metadata": {
        "id": "4JheIYlZ-8ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj_r2"
      ],
      "metadata": {
        "id": "GNOaKu-S-_-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(y_test,test_preds)"
      ],
      "metadata": {
        "id": "0WVO-KfW_CrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = reg_optimal_model.feature_importances_\n",
        "importance_dict = {'Feature' : list(X_train.columns),\n",
        "                   'Feature Importance' : importances}\n",
        "importance_df = pd.DataFrame(importance_dict)\n",
        "important_features=importance_df.sort_values(by=['Feature Importance'],ascending=False).head(20)\n",
        "imp_features = important_features['Feature'].tolist()\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(y = important_features['Feature'], x = important_features['Feature Importance'] )\n",
        "plt.title('10 Most Important features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vDoLKlWL_GXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Mean Squared Error (MSE): ',mean_squared_error(y_test, test_preds))\n",
        "print('Mean Absolute Error (MAE): ',mean_absolute_error(y_test, test_preds))\n",
        "print('Root Mean Squared Error (MSE): ',np.sqrt(mean_squared_error(y_test, test_preds)))\n",
        "print('R2 Score: ',r2_test)\n",
        "print('Adjusted R2 Score: ',adj_r2)"
      ],
      "metadata": {
        "id": "u-vaw6sI_Yie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to make a dataframe of evaluation matrics for a model\n",
        "def make_dataFrame(model, df,Model_name,X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_train):\n",
        "\n",
        "  '''This function takes arugment as model name and training and testing\n",
        "    data and a datafram and returns a dataframe after appending the entries of\n",
        "    evaluation matrics for a model\n",
        "  '''\n",
        "  df = pd.DataFrame(columns=['Model Name','Train Score','test_score','R2 Score','Adjusted R2 Score','MSE','MAE'])\n",
        "  model_train_preds = model.predict(X_train)\n",
        "  model_test_preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "  train_score = model.score(y_train,model_train_preds)\n",
        "  test_score = model.score(y_test,model_test_preds)\n",
        "  r2 = r2_score(y_test,model_trainProb_preds)\n",
        "  adjusted_r2 = 1-(1-r2_score(y_test, model_test_preds))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))\n",
        "  mse =  mean_squared_error(y_test, model_train_preds)\n",
        "  mae = mean_absolute_error(y_test, model_train_preds)\n",
        "  metrix_dict = {'model_name':Model_name,\n",
        "                 'Train Score':train_score,\n",
        "                 'Test Score':test_score,\n",
        "                 'R2 Score':r2,\n",
        "                 'Adjusted R2 Score':adjusted_r2,\n",
        "                 'MSE':mse,\n",
        "                 'MAE':mae,\n",
        "               }\n",
        "  df = df.append(metrix_dict,ignore_index = True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "Amv3npPa_BTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of instances of all the models with model name as value\n",
        "models = {model:\"Linear Regression\",lasso:\"Lasso Regression\",ridge_regressor: \"Ridge Regression\",rf_optimal_model: \"Random Forest Regressor\",}\n"
      ],
      "metadata": {
        "id": "Hu6fEtvc_FV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used diffent type of regression algorithms to train our model like, Linear Regression, Regularized linear regression (Ridge and Lasso), GBM,Random Forest Regressor, XGboost regresssor. and Also we tuned the parameters of Random forest regressor and XGboost regressor and also found the important features for training the model. Out of them XGboost with tuned hyperparameters gave the best result.\n",
        "###Why?\n",
        "#####Using XGBoost with tuned parameters for transport demand prediction in Nairobi can be an excellent choice for several reasons:\n",
        "\n",
        "Predictive Accuracy: XGBoost is known for its high predictive accuracy. Through careful hyperparameter tuning, you can fine-tune the model's parameters to fit the specific characteristics of the transport demand data in Nairobi. This leads to more accurate predictions, which is essential for effective transportation planning.\n",
        "\n",
        "Complex Relationships: XGBoost can capture complex relationships and interactions between various factors affecting transport demand, such as traffic patterns, economic conditions, population growth, and infrastructure changes. By tuning its hyperparameters, you can allow XGBoost to explore and model these complexities effectively.\n",
        "\n",
        "Regularization: XGBoost offers several regularization techniques, which can help control overfitting and improve the model's generalization to new data. This is particularly important when dealing with limited transportation data, as it helps prevent the model from fitting noise in the data.\n",
        "\n",
        "Feature Importance: XGBoost provides a measure of feature importance, indicating which factors have the most significant impact on the predictions. Understanding which features are most influential can guide decision-makers in Nairobi to focus their efforts and resources on addressing the most critical factors affecting transport demand.\n",
        "\n",
        "Scalability: XGBoost is scalable and can handle large datasets. Nairobi is a densely populated city with substantial transportation data, and XGBoost's efficiency can be advantageous in managing and analyzing this data.\n",
        "\n",
        "Speed and Efficiency: XGBoost is designed for efficiency and often offers competitive predictive performance with relatively fast training times compared to other machine learning algorithms. This efficiency can be critical for timely predictions and decision-making in the context of transport management.\n",
        "\n",
        "Hyperparameter Tuning: Hyperparameter tuning, performed via techniques like Grid Search, Random Search, or Bayesian optimization, allows you to find the best set of hyperparameters for your specific transport demand prediction task. Tuning can significantly improve the model's performance and robustness.\n",
        "\n",
        "Ensemble Learning: XGBoost is an ensemble learning algorithm. It combines the predictions of multiple decision trees to create a more accurate final prediction. This ensemble approach can further enhance the model's performance, reduce overfitting, and provide stable and reliable predictions.\n",
        "\n",
        "Proven Effectiveness: XGBoost has been used successfully in various real-world applications and machine learning competitions, demonstrating its effectiveness in a wide range of predictive modeling tasks.\n",
        "\n",
        "Community and Resources: XGBoost has a strong community of users and a wealth of online resources, including documentation and tutorials, making it easier to implement and fine-tune the model effectively.\n",
        "\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above we conclude that,this resulting model can be used by Mobiticket and bus operators to aticipate for the tickets for ceratin rides.We preprocesed the data to apply regression models for forecasting the speed of vehicles and distance between the source and destination."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}